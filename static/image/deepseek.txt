Многие говорят о DeepSeek R-1 - новой языковой ИИ-модели с открытым исходным кодом, созданной китайской ИИ-компанией DeepSeek. Некоторые пользователи утверждают, что по возможностям рассуждения она не уступает или даже превосходит модель o1 от OpenAI.

В настоящее время DeepSeek можно использовать бесплатно, что является отличной новостью для пользователей, но вызывает некоторые вопросы. Как при таком резком росте числа пользователей они справляются с затратами на сервера?

Ведь эксплуатационные расходы на оборудование не могут быть дешевыми, верно?

Единственный логичный ответ здесь - данные. Данные - это жизненная сила ИИ-моделей. Вероятно, они собирают данные о пользователях, чтобы использовать их для монетизации своей модели в будущем.

Поэтому, если вы беспокоитесь о конфиденциальности данных, но при этом хотите использовать R1, не предоставляя свои данные, лучший способ - запустить модель локально.

Что такое DeepSeek R-1?
Пару дней назад была представлена модель Deepseek R-1 с открытым исходным кодом, то есть любой желающий может взять базовый код, адаптировать его и даже доработать под свои нужды.

С технической точки зрения Deepseek R-1 (часто сокращенно R1) основана на большой базовой модели под названием DeepSeek-V3. Затем лаборатория усовершенствовала эту модель с помощью комбинации контролируемой тонкой настройки (SFT) на высококачественных данных, размеченных людьми, и обучения с подкреплением (RL).

В результате получился чатбот, который может обрабатывать сложные запросы, раскрывать логику сложных вопросов (иногда более прозрачно, чем другие модели) и даже отображать код в интерфейсе чата для быстрого тестирования.

Честно говоря, это очень впечатляет, особенно для модели с открытым исходным кодом.

Как запустить локально
Для локального запуска DeepSeek R-1 мы будем использовать инструмент под названием Ollama.

Ollama - это бесплатный инструмент с открытым исходным кодом, который позволяет пользователям запускать большие языковые модели (LLM) локально на своих компьютерах. Он доступен для macOS, Linux и Windows.

Перейдите на официальный сайт Ollama и нажмите на кнопку «Download». Установите его на свой компьютер.